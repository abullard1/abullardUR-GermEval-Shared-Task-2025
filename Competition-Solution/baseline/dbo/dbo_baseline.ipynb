{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea58410780ae9826",
   "metadata": {},
   "source": [
    "# Baseline system of DBO detection model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722ca48",
   "metadata": {},
   "source": [
    "The Jupyter notebook `dbo_baseline.ipynb` contains the code for creating the baseline system for fine-grained detection of various types of attacks on the **free democratic basic order (DBO)** (**subtask 2** of the Shared Task on Harmful Content Detection). An Support Vector Machine (SVM) with a linear kernel using TF-IDF features was chosen as the classifier. The notebook includes the training of the system as well as the prediction on the test data and the evaluation. \n",
    "\n",
    "The programme was tested using Python version 3.12.9. Executing the following two lines of code will install all necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a761abe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "pandas==2.2.3\n",
    "spacy==3.8.2\n",
    "scikit-learn==1.6.1\n",
    "textblob==0.15.3\n",
    "textblob-de==0.4.3\n",
    "sentence-transformers==4.1.0\n",
    "nltk==3.9.1\n",
    "numpy==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57793d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4188b91ac4619b08",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29074fd1",
   "metadata": {},
   "source": [
    "First, the training data was read in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>DBO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Der Riese ist geweckt,mit oder ohne Verräter u...</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gut Ding will Weile haben...  (y)</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sollen sie doch nach Saudi Arabien</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volle Zustimmung.??</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mal sehen wann wir an der Erderwärmung schuld ...</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description      DBO\n",
       "0  Der Riese ist geweckt,mit oder ohne Verräter u...  nothing\n",
       "1                  Gut Ding will Weile haben...  (y)  nothing\n",
       "2                 Sollen sie doch nach Saudi Arabien  nothing\n",
       "3                                Volle Zustimmung.??  nothing\n",
       "4  Mal sehen wann wir an der Erderwärmung schuld ...  nothing"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = 'dbo_train.csv' # Path needs to be adjusted  \n",
    "\n",
    "# Reading in training data\n",
    "train_dbo = pd.read_csv(filename, sep=';')\n",
    "train_dbo.drop('id', axis=1, inplace=True)\n",
    "train_dbo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e87e6f",
   "metadata": {},
   "source": [
    "The class distribution of the training data was analysed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57359690e13f9f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Frequency  Percentage\n",
      "DBO                              \n",
      "nothing          6277       84.21\n",
      "criticism         804       10.79\n",
      "agitation         313        4.20\n",
      "subversive         60        0.80\n"
     ]
    }
   ],
   "source": [
    "# Absolute number of instances in each class \n",
    "class_counts_dbo = train_dbo[\"DBO\"].value_counts()\n",
    "\n",
    "# Relative number of instances in each class \n",
    "class_percent_dbo = train_dbo['DBO'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Summarise into a dataframe\n",
    "class_table_dbo = pd.DataFrame({\n",
    "    'Frequency': class_counts_dbo,\n",
    "    'Percentage': class_percent_dbo.round(2)\n",
    "})\n",
    "\n",
    "print(class_table_dbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4a3a2",
   "metadata": {},
   "source": [
    "The training data was then pre-processed. First, basic cleaning steps (removing URLs, mentions, hashtags, numbers and redundant whitespace) were carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e17c0a4b7c0b804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>DBO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>der riese ist geweckt,mit oder ohne verräter u...</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gut ding will weile haben... (y)</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sollen sie doch nach saudi arabien</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>volle zustimmung.??</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mal sehen wann wir an der erderwärmung schuld ...</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description      DBO\n",
       "0  der riese ist geweckt,mit oder ohne verräter u...  nothing\n",
       "1                   gut ding will weile haben... (y)  nothing\n",
       "2                 sollen sie doch nach saudi arabien  nothing\n",
       "3                                volle zustimmung.??  nothing\n",
       "4  mal sehen wann wir an der erderwärmung schuld ...  nothing"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def text_clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'\\d+', ' NUM ', text)  # Replace numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "\n",
    "# Application of pre-processing steps to the training data\n",
    "train_dbo['description'] = train_dbo['description'].apply(text_clean)\n",
    "train_dbo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f912b6f",
   "metadata": {},
   "source": [
    "Furthermore, the class labels (*agitation*, *criticism*, *nothing*, *subversive*) were mapped to numerical values (0, 1, 2, 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c64abde75045a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "train_dbo['DBO_encoded']= train_dbo['DBO'].apply(lambda x: ['agitation', 'criticism', 'nothing', 'subversive'].index(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5523f6fa2a36610",
   "metadata": {},
   "source": [
    "## 2. TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47215b9",
   "metadata": {},
   "source": [
    "TF-IDF weighted bag-of-phrases representation was chosen as the feature, with tweets tokenised into unigrams and bigrams. The vocabulary comprised the 5,000 most common terms in the training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc9d2212abefd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7454, 5000) (7454,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_dbo['description'])\n",
    "y_train = train_dbo['DBO_encoded']\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91305a",
   "metadata": {},
   "source": [
    "## 3. Model training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e2c47c",
   "metadata": {},
   "source": [
    "To counteract the strong class imbalance in the training data set, a cost-sensitive SVM was used. Misclassifications for the underrepresented classes (especially subversion and agitation) were penalised more heavily than for the other two classes to prevent the Support Vector Machine (SVM) from assigning the tweets only to the overrepresented classes. The class weights were initially calculated based on the proportion of instances of this class in the training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cde2301ac0c7ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: np.float64(5.953674121405751),\n",
       " 1: np.float64(2.317786069651741),\n",
       " 2: np.float64(0.2968774892464553),\n",
       " 3: np.float64(31.058333333333334)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "# Calculate the class weights for each class\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9b3c8",
   "metadata": {},
   "source": [
    "Subsequently, parameter C, which determines the data points of which class the classifier must pay particular attention to for correct classification, was set for each class depending on the calculated class weights. An SVM with linear kernel was trained using the TF-IDF representation of the tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af99d091f8a5c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Training svm \n",
    "svm_model = SVC(kernel='linear', class_weight=class_weights_dict)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d3d1111fdf9ab",
   "metadata": {},
   "source": [
    "## 5. Prediction on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b378b",
   "metadata": {},
   "source": [
    "Predictions were then made on the test data using the trained SVM model. For this purpose, the test data was preprocessed in the same way as the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecd40427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the test data\n",
    "filename = \"dbo_test.csv\" # Path needs to be adjusted \n",
    "test_dbo = pd.read_csv(filename, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a0cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the test data\n",
    "test_dbo['description'] = test_dbo['description'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09587d66",
   "metadata": {},
   "source": [
    "The test data was then also TF-IDF vectorised (using the vocabulary from the training data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc55ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorisation of test data\n",
    "test_dbo_idf_vec = vectorizer.transform(test_dbo['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add809c",
   "metadata": {},
   "source": [
    "The extracted features of the test data are passed to the gradient boosting model for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a097660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction \n",
    "y_pred = svm_model.predict(test_dbo_idf_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a8d825857b97c",
   "metadata": {},
   "source": [
    "## 6. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafbe092",
   "metadata": {},
   "source": [
    "The predictions based on the test data were compared with the gold standard and some basic evaluation metrics were calculated. The results achieved serve as a guide and baseline for the competition participants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2a4ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the gold standard \n",
    "filename = \"dbo_gold.csv\" # Path needs to be adjusted \n",
    "gold_dbo = pd.read_csv(filename, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d96eb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels \n",
    "gold_dbo['DBO_encoded']= gold_dbo['DBO'].apply(lambda x: ['agitation', 'criticism', 'nothing', 'subversive'].index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ee42ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the actual label of the test data\n",
    "y_true = gold_dbo['DBO_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e5566",
   "metadata": {},
   "source": [
    "The macro metric F1 serves as the main evaluation metric used to calculate the ranking on the leaderboard for the competition. In addition, other evaluation metrics such as precision and recall are calculated for the individual classes, as well as the macro and weighted average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62f2b5a1b6dc4fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.46      0.36       134\n",
      "           1       0.36      0.65      0.47       345\n",
      "           2       0.94      0.82      0.88      2690\n",
      "           3       0.60      0.12      0.20        25\n",
      "\n",
      "    accuracy                           0.78      3194\n",
      "   macro avg       0.55      0.51      0.47      3194\n",
      "weighted avg       0.85      0.78      0.80      3194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = svm_model.predict(test_dbo_idf_vec)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
